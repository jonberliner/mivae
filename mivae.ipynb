{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mivae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsgX3XfsA2Xw79ssZpvz2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonberliner/mivae/blob/master/mivae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7eMX2c8Faca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import distributions as D\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import squeezenet1_1, resnet18\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "rng = np.random.RandomState()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPJe7qQmF6IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define statics\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "INPUT_SIZE = 784\n",
        "DIM_X = 3\n",
        "SIZE_X = 28\n",
        "BACKBONE_OUTPUT_SIZE = 256 * 2\n",
        "NUM_Z_PARTITIONS = 2\n",
        "Z1_SIZE = 13\n",
        "Z2_SIZE = 17\n",
        "DIM_Z = Z1_SIZE + Z2_SIZE"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDwZCPi_FzgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define encoder (choice of backbone is arbitrary)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "            backbone: nn.Module,\n",
        "            dim_x: int,\n",
        "            dim_z: int,\n",
        "            backbone_output_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.dim_x = dim_x\n",
        "        self.dim_z = dim_z\n",
        "        self.backbone_output_dim = backbone_output_dim\n",
        "\n",
        "        self.readout = nn.Linear(self.backbone_output_dim, self.dim_z)\n",
        "\n",
        "    def forward(self, \n",
        "                inputs: torch.Tensor,\n",
        "                return_backbone_outputs: Optional[bool]=False) -> torch.Tensor:\n",
        "        bb_outputs = self.backbone(inputs)\n",
        "        outputs = bb_outputs\n",
        "        while len(outputs.shape) > 2:\n",
        "            outputs = torch.mean(outputs, dim=-1)\n",
        "        outputs = self.readout(outputs)\n",
        "        if return_backbone_outputs:\n",
        "            return maxes, bb_outputs\n",
        "        else:\n",
        "            return outputs\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x9UXx2FFs0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define a decoder (choice of architecture is arbitrary)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "            dim_z: int,\n",
        "            dim_x: int,\n",
        "            x_size: int=28) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.readin = nn.Conv2d(dim_z, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.resnet = resnet18(pretrained=False)\n",
        "        self.readout = nn.Conv2d(512, dim_x * 2, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.model = nn.Sequential(*[\n",
        "            self.readin,\n",
        "            self.resnet.bn1,\n",
        "            self.resnet.relu,\n",
        "            self.resnet.layer1,\n",
        "            self.resnet.layer2,\n",
        "            self.resnet.layer3,\n",
        "            self.resnet.layer4,\n",
        "            self.readout])\n",
        "\n",
        "        self.dim_z = dim_z\n",
        "        self.dim_x = dim_x\n",
        "        self.x_size = x_size\n",
        "\n",
        "    def forward(self, zs: torch.Tensor) -> torch.Tensor:\n",
        "        inputs = torch.reshape(zs, (-1, self.dim_z, 1, 1))\\\n",
        "                      .expand(-1, self.dim_z, self.x_size*8, self.x_size*8)\n",
        "        outputs = self.model(inputs)\n",
        "        assert outputs.shape[2] == self.x_size\n",
        "        return outputs\n",
        "            "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emYB0oF4GRKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12qdjI4jA__E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### prep dataset and data transforms\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        lambda x: x.expand(3, -1, -1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE),\n",
        "        transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        lambda x: x.expand(3, -1, -1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset = FashionMNIST('./FashionMNIST', download=True, transform=data_transforms['train'])\n",
        "data_loader = DataLoader(dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_9-qcCBF-1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### init encoders and decoder\n",
        "squeezenet1 = squeezenet1_1(pretrained=True).features\n",
        "squeezenet2 = squeezenet1_1(pretrained=True).features\n",
        "\n",
        "# Z1_SIZE-way normal distr\n",
        "encoder1 = Encoder(squeezenet1, INPUT_SIZE, Z1_SIZE * 2, BACKBONE_OUTPUT_SIZE)\n",
        "# Z2_SIZE-way normal distr\n",
        "encoder2 = Encoder(squeezenet2, INPUT_SIZE, Z2_SIZE * 2, BACKBONE_OUTPUT_SIZE)\n",
        "\n",
        "decoder = Decoder(DIM_Z, DIM_X, SIZE_X)\n",
        "\n",
        "encoder1 = encoder1.to(device)\n",
        "encoder2 = encoder2.to(device)\n",
        "\n",
        "decoder = decoder.to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDW1VIAYBENe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### forward pass through VAE\n",
        "\n",
        "# set priors (can be any distr can call rsample on)\n",
        "p_x = D.Normal(\n",
        "            loc=torch.tensor([0.485, 0.456, 0.406])\\\n",
        "                     .reshape([1, 3, 1, 1]).to(device),\n",
        "            scale=torch.tensor([0.229, 0.224, 0.225])\\\n",
        "                     .reshape([1, 3, 1, 1]).to(device))\n",
        "\n",
        "p_z1 = D.Normal(\n",
        "            loc=torch.zeros(Z1_SIZE).to(device), \n",
        "            scale=torch.ones(Z1_SIZE).to(device))\n",
        " \n",
        "p_z2 = D.Normal(\n",
        "            loc=torch.zeros(Z2_SIZE).to(device),\n",
        "            scale=torch.ones(Z2_SIZE).to(device))\n",
        "\n",
        "inputs = dataset[0][0].unsqueeze(0)\n",
        "\n",
        "for xx, yy in data_loader:\n",
        "    inputs = xx.to(device)\n",
        "\n",
        "    # first pass of inference for VAE loss\n",
        "    inputs = inputs.to(device)\n",
        "    batch_size = inputs.shape[0]\n",
        "\n",
        "    inferred11 = encoder1(inputs)\n",
        "    inferred21 = encoder2(inputs)\n",
        "\n",
        "    # draw from p(z|x) for all siblings z1,...,zn that constitute z\n",
        "    p_z1_given_x = D.Normal(\n",
        "            loc=inferred11[:, :Z1_SIZE], \n",
        "            scale=F.softplus(inferred11[:, Z1_SIZE:]) + 1e-4)\n",
        "\n",
        "    p_z2_given_x = D.Normal(\n",
        "            loc=inferred21[:, :Z2_SIZE], \n",
        "            scale=F.softplus(inferred21[:, Z2_SIZE:]) + 1e-4)\n",
        "\n",
        "    z1_given_x = p_z1_given_x.rsample()\n",
        "    z2_given_x = p_z2_given_x.rsample()\n",
        "\n",
        "    # combine z1,...,zn into agg'd z for generative model\n",
        "    z_given_x = torch.cat([z1_given_x, z2_given_x], dim=1)\n",
        "    p_recon_x_given_z_logits = decoder(z_given_x)\n",
        "    p_recon_x_given_z = D.Normal(\n",
        "        loc=p_recon_x_given_z_logits[:, :DIM_X], \n",
        "        scale=F.softplus(p_recon_x_given_z_logits[:, DIM_X:]) + 1e-4)\n",
        "\n",
        "    # calc standard vae loss\n",
        "    vae_loss_z1 = D.kl_divergence(p_z1_given_x, p_z1)\n",
        "    vae_loss_z2 = D.kl_divergence(p_z2_given_x, p_z2)\n",
        "    vae_loss_x = D.kl_divergence(p_recon_x_given_z, p_x)\n",
        "\n",
        "    \n",
        "    # second pass inference for MIVAE Loss\n",
        "\n",
        "    # choose which zi will be prior and which posterior\n",
        "    if rng.rand() > 0.5:\n",
        "        # z1 draws from p(z1|x), z2 from p(z2)\n",
        "        post = 1\n",
        "        z1 = p_z1_given_x.rsample()\n",
        "        z2 = p_z2.rsample(sample_shape=torch.Size([batch_size]))\n",
        "    else:\n",
        "        post = 2\n",
        "        z1 = p_z1.rsample(sample_shape=torch.Size([batch_size]))\n",
        "        z2 = p_z2_given_x.rsample()\n",
        "\n",
        "    # generate synthetic sample for mutual info loss\n",
        "    z_given_x_2 = torch.cat([z1, z2], dim=1)\n",
        "    \n",
        "    # get distr for x | z_given_x_2\n",
        "    p_x2_given_z_logits = decoder(z_given_x_2)\n",
        "    p_x2_given_z = D.Normal(\n",
        "        loc=p_x2_given_z_logits[:, :DIM_X], \n",
        "        scale=F.softplus(p_x2_given_z_logits[:, DIM_X:]) + 1e-4)\n",
        "    # draw synthetic x2\n",
        "    x2_given_z = p_x2_given_z.rsample()\n",
        "\n",
        "    # infer from synthetic sample\n",
        "    inferred12 = encoder1(x2_given_z)        \n",
        "    inferred22 = encoder2(x2_given_z)\n",
        "\n",
        "    p_z1_given_x2 = D.Normal(\n",
        "        loc=inferred12[:, :Z1_SIZE], \n",
        "        scale=F.softplus(inferred12[:, Z1_SIZE:]) + 1e-4)\n",
        "\n",
        "    p_z2_given_x2 = D.Normal(\n",
        "        loc=inferred22[:, Z2_SIZE:], \n",
        "        scale=F.softplus(inferred22[:, Z2_SIZE:]) + 1e-4)\n",
        "    \n",
        "    # calc mutual info loss\n",
        "    if post == 1:\n",
        "        mi_loss_z1 = D.kl_divergence(p_z1_given_x2, p_z1_given_x)\n",
        "        mi_loss_z2 = D.kl_divergence(p_z2_given_x2, p_z2)\n",
        "    elif post == 2:\n",
        "        mi_loss_z1 = D.kl_divergence(p_z1_given_x2, p_z1)\n",
        "        mi_loss_z2 = D.kl_divergence(p_z2_given_x2, p_z2_given_x)\n",
        "\n",
        "    mi_loss_x = D.kl_divergence(p_x2_given_z, p_x)\n",
        "\n",
        "    # clip losses for stability\n",
        "    vae_loss_z1 = vae_loss_z1.clamp(max=100.)\n",
        "    vae_loss_z2 = vae_loss_z2.clamp(max=100.)\n",
        "    vae_loss_x = vae_loss_x.clamp(max=100.)\n",
        "\n",
        "    mi_loss_z1 = mi_loss_z1.clamp(max=100.)\n",
        "    mi_loss_z2 = mi_loss_z2.clamp(max=100.)\n",
        "    mi_loss_x = mi_loss_x.clamp(max=100.)\n",
        "\n",
        "    # add together losses\n",
        "    vae_loss = vae_loss_z1.mean() + vae_loss_z2.mean() + vae_loss_x.mean()\n",
        "    mi_loss = mi_loss_z1.mean() + mi_loss_z2.mean() + mi_loss_x.mean()\n",
        "\n",
        "    losses = vae_loss + mi_loss\n",
        "    loss = losses.sum()\n",
        "\n",
        "    print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL6-HZX-a83a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}