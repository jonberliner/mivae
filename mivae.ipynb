{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mivae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOe6u+THkha55U8Tg0mBzDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonberliner/mivae/blob/master/mivae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6omfcHv-A-zV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "99e8ba49-12f8-49db-fd95-85a3430ad22c"
      },
      "source": [
        "!pip install pytorch-ignite tqdm\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/8e/08569347023611e40e62a14162024ca6238d42cb528b2302f84d662a2033/pytorch_ignite-0.4.1-py2.py3-none-any.whl (166kB)\n",
            "\r\u001b[K     |██                              | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7eMX2c8Faca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import distributions as D\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import squeezenet1_1, resnet18\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import numpy\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPJe7qQmF6IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define statics\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "INPUT_SIZE = 784\n",
        "DIM_X = 3\n",
        "SIZE_X = 28\n",
        "BACKBONE_OUTPUT_SIZE = 256 * 2\n",
        "NUM_Z_PARTITIONS = 2\n",
        "Z1_SIZE = 13\n",
        "Z2_SIZE = 17\n",
        "DIM_Z = Z1_SIZE + Z2_SIZE"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDwZCPi_FzgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define encoder (choice of backbone is arbitrary)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "            backbone: nn.Module,\n",
        "            dim_x: int,\n",
        "            dim_z: int,\n",
        "            backbone_output_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.dim_x = dim_x\n",
        "        self.dim_z = dim_z\n",
        "        self.backbone_output_dim = backbone_output_dim\n",
        "\n",
        "        self.readout = nn.Linear(self.backbone_output_dim, self.dim_z)\n",
        "\n",
        "    def forward(self, \n",
        "                inputs: torch.Tensor,\n",
        "                return_backbone_outputs: Optional[bool]=False) -> torch.Tensor:\n",
        "        bb_outputs = self.backbone(inputs)\n",
        "        outputs = bb_outputs\n",
        "        while len(outputs.shape) > 2:\n",
        "            outputs = torch.mean(outputs, dim=-1)\n",
        "        outputs = self.readout(outputs)\n",
        "        if return_backbone_outputs:\n",
        "            return maxes, bb_outputs\n",
        "        else:\n",
        "            return outputs\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x9UXx2FFs0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define a decoder (choice of architecture is arbitrary)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "            dim_z: int,\n",
        "            dim_x: int,\n",
        "            x_size: int=28) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.readin = nn.Conv2d(dim_z, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.resnet = resnet18(pretrained=False)\n",
        "        self.readout = nn.Conv2d(512, dim_x, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.model = nn.Sequential(*[\n",
        "            self.readin,\n",
        "            self.resnet.bn1,\n",
        "            self.resnet.relu,\n",
        "            self.resnet.layer1,\n",
        "            self.resnet.layer2,\n",
        "            self.resnet.layer3,\n",
        "            self.resnet.layer4,\n",
        "            self.readout])\n",
        "\n",
        "        self.dim_z = dim_z\n",
        "        self.dim_x = dim_x\n",
        "        self.x_size = x_size\n",
        "\n",
        "    def forward(self, zs: torch.Tensor) -> torch.Tensor:\n",
        "        inputs = torch.reshape(zs, (-1, self.dim_z, 1, 1))\\\n",
        "                      .expand(-1, self.dim_z, self.x_size*8, self.x_size*8)\n",
        "        outputs = self.model(inputs)\n",
        "        assert outputs.shape[2] == self.x_size\n",
        "        return outputs\n",
        "            "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emYB0oF4GRKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12qdjI4jA__E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### prep dataset and data transforms\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        lambda x: x.expand(3, -1, -1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE),\n",
        "        transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        lambda x: x.expand(3, -1, -1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset = FashionMNIST('./FashionMNIST', download=True, transform=data_transforms['train'])\n",
        "dataloader = DataLoader(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_9-qcCBF-1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### init encoders and decoder\n",
        "squeezenet1 = squeezenet1_1(pretrained=True).features\n",
        "squeezenet2 = squeezenet1_1(pretrained=True).features\n",
        "\n",
        "encoders = {}\n",
        "for ii in range(len(NUM_Z_PARTITIONS)):\n",
        "    encoders.a\n",
        "# Z1_SIZE-way normal distr\n",
        "encoder1 = Encoder(squeezenet1, INPUT_SIZE, Z1_SIZE * 2, BACKBONE_OUTPUT_SIZE)\n",
        "# Z2_SIZE-way normal distr\n",
        "encoder2 = Encoder(squeezenet2, INPUT_SIZE, Z2_SIZE * 2, BACKBONE_OUTPUT_SIZE)\n",
        "\n",
        "decoder = Decoder(DIM_Z, DIM_X, SIZE_X)\n",
        "\n",
        "encoder1 = encoder1.to(device)\n",
        "encoder2 = encoder2.to(device)\n",
        "\n",
        "decoder = decoder.to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDW1VIAYBENe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "6ca6b287-abea-463f-9dc3-b710c5df7739"
      },
      "source": [
        "### forward pass through VAE\n",
        "\n",
        "# set priors (can be any distr can call rsample on)\n",
        "p_x = D.Normal(\n",
        "            loc=torch.tensor([0.485, 0.456, 0.406]),\n",
        "            scale=torch.tensor[0.229, 0.224, 0.225]))\n",
        "\n",
        "p_z1 = D.Normal(\n",
        "            loc=torch.zeros(Z1_SIZE), \n",
        "            scale=torch.ones(Z1_SIZE))\n",
        " \n",
        "p_z2 = D.Normal(\n",
        "            loc=torch.zeros(Z2_SIZE),\n",
        "            scale=torch.ones(Z2_SIZE))\n",
        "\n",
        "inputs = dataset[0][0].unsqueeze(0)\n",
        "\n",
        "for xx, yy in data_loader:\n",
        "    inputs = xx.to(device)\n",
        "\n",
        "    # first pass of inference for VAE loss\n",
        "    inputs = inputs.to(device)\n",
        "    batch_size = inputs.shape[0]\n",
        "\n",
        "    inferred11 = encoder1(inputs)\n",
        "    inferred21 = encoder2(inputs)\n",
        "\n",
        "    # draw from p(z|x) for all siblings z1,...,zn that constitute z\n",
        "    p_z1_given_x_1 = D.Normal(\n",
        "            loc=inferred11[:, :Z1_SIZE], \n",
        "            scale=F.softplus(inferred11[:, Z1_SIZE:]) + 1e-4)\n",
        "\n",
        "    p_z2_given_x_1 = D.Normal(\n",
        "            loc=inferred21[:, :Z2_SIZE], \n",
        "            scale=F.softplus(inferred21[:, Z2_SIZE:]) + 1e-4)\n",
        "\n",
        "    z1_given_x_1 = p_z1_given_x_1.rsample()\n",
        "    z2_given_x_1 = p_z2_given_x_1.rsample()\n",
        "\n",
        "    # combine z1,...,zn into agg'd z for generative model\n",
        "    z_given_x_1 = torch.cat([z1_given_x_1, z2_given_x_1], dim=1)\n",
        "    p_recon_x_given_z = decoder(z_given_x_1)\n",
        "\n",
        "    # calc standard vae loss\n",
        "    vae_loss_z1 = D.kl_divergence(p_z1_given_x, p_z1)\n",
        "    vae_loss_z2 = D.kl_divergence(p_z2_given_x, p_z2)\n",
        "    vae_loss_x = D.kl_divergence(p_recon_x_given_z, p_x)\n",
        "\n",
        "    \n",
        "    # second pass inference for MIVAE Loss\n",
        "\n",
        "    # choose which zi will be prior and which posterior\n",
        "    if rng.rand() > 0.5:\n",
        "        # z1 draws from p(z1|x), z2 from p(z2)\n",
        "        post = 1\n",
        "        z1 = z1_given_x_1.rsample()\n",
        "        z2 = p_z2.rsample(size=batch_size)\n",
        "    else:\n",
        "        post = 2\n",
        "        z1 = p_z1.rsample(size=batch_size)\n",
        "        z2 = p_z2_given_x.rsample()\n",
        "\n",
        "    # generate synthetic sample for mutual info loss\n",
        "    z_given_x_2 = torch.cat([z1, z2])\n",
        "    \n",
        "    # get distr for x | z_given_x_2\n",
        "    p_x2_given_z_logits = decoder(z_given_x_2)\n",
        "    p_x2_given_z = D.Normal(\n",
        "        loc=p_x2_given_z_logits[:, :SIZE_X], \n",
        "        scale=F.softplus(p_x2_given_z_logits[:, SIZE_X:]) + 1e-4)\n",
        "    # draw synthetic x2\n",
        "    x2_given_z = p_x2_given_z.rsample()\n",
        "\n",
        "    # infer from synthetic sample\n",
        "    inferred12 = encoder1(x2)        \n",
        "    inferred22 = encoder2(x2)\n",
        "\n",
        "    p_z1_given_x2 = D.Normal(\n",
        "        loc=inferred12[:, :Z2_SIZE], \n",
        "        scale=F.softplus(inferred12[:, Z2_SIZE:]) + 1e-4)\n",
        "\n",
        "    p_z2_given_x2 = D.Normal(\n",
        "        loc=inferred22[:, :Z2_SIZE], \n",
        "        scale=F.softplus(inferred22[:, Z2_SIZE:]) + 1e-4)\n",
        "    \n",
        "    # calc mutual info loss\n",
        "    if post == 1:\n",
        "        mi_loss_z1 = D.kl_divergence(p_z1_given_x2, p_z1_given_x)\n",
        "        mi_loss_z2 = D.kl_divergence(p_z2_given_x2, p_z2)\n",
        "    elif post == 2:\n",
        "        mi_loss_z1 = D.kl_divergence(p_z1_given_x2, p_z1)\n",
        "        mi_loss_z2 = D.kl_divergence(p_z2_given_x2, p_z2_given_x)\n",
        "\n",
        "    mi_loss_x = D.kl_divergence(p_x2_given_z, p_x)\n",
        "\n",
        "    # clip losses for stability\n",
        "    vae_loss_z1 = vae_loss_z1.clamp(max=100.)\n",
        "    vae_loss_z2 = vae_loss_z2.clamp(max=100.)\n",
        "    vae_loss_x = vae_loss_x.clamp(max=100.)\n",
        "\n",
        "    mi_loss_z1 = mi_loss_z1.clamp(max=100.)\n",
        "    mi_loss_z2 = mi_loss_z2.clamp(max=100.)\n",
        "    mi_loss_x = mi_loss_x.clamp(max=100.)\n",
        "\n",
        "    # add together losses\n",
        "    vae_loss = vae_loss_z1 + vae_loss_z2 + vae_loss_x\n",
        "    mi_loss = mi_loss_z1 + mi_loss_z2 + mi_loss_x"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6caa398d3080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m p_x = D.Normal(\n\u001b[1;32m      5\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             scale=[0.229, 0.224, 0.225])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input arguments must all be instances of numbers.Number or torch.tensor.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input arguments must all be instances of numbers.Number or torch.tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n83u2MfhKBBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}